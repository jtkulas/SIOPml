{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a7228f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>rating_chooses_appropriate_action</th>\n",
       "      <th>rating_commits_to_action</th>\n",
       "      <th>rating_gathers_information</th>\n",
       "      <th>rating_identifies_issues_opportunities</th>\n",
       "      <th>rating_interprets_information</th>\n",
       "      <th>rating_involves_others</th>\n",
       "      <th>rating_decision_making_final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi Tracy, This sounds very ionteresting, prio...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi Tracy, I am happy to see we have a self mo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J.J please can you work with her for two mor...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi Paxton Let me talk to Debby first, before...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JJ HR along with myself and the Final Assem...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>Dear Tracey,I wanted to take the time to than...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>Hi Tracy - thanks for your note and for shari...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>Dear Tracey,Thanks for sharing the data.We do...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>Hi Tracy, Thanks for sharing customer satisfa...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>Tracey,This is fantastic work, excellent init...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1466 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              predictor   \n",
       "0      Hi Tracy, This sounds very ionteresting, prio...  \\\n",
       "1      Hi Tracy, I am happy to see we have a self mo...   \n",
       "2       J.J please can you work with her for two mor...   \n",
       "3       Hi Paxton Let me talk to Debby first, before...   \n",
       "4        JJ HR along with myself and the Final Assem...   \n",
       "...                                                 ...   \n",
       "1461   Dear Tracey,I wanted to take the time to than...   \n",
       "1462   Hi Tracy - thanks for your note and for shari...   \n",
       "1463   Dear Tracey,Thanks for sharing the data.We do...   \n",
       "1464   Hi Tracy, Thanks for sharing customer satisfa...   \n",
       "1465   Tracey,This is fantastic work, excellent init...   \n",
       "\n",
       "      rating_chooses_appropriate_action  rating_commits_to_action   \n",
       "0                                   2.0                         2  \\\n",
       "1                                   4.0                         3   \n",
       "2                                   2.0                         2   \n",
       "3                                   3.0                         3   \n",
       "4                                   3.0                         3   \n",
       "...                                 ...                       ...   \n",
       "1461                                2.0                         2   \n",
       "1462                                4.0                         4   \n",
       "1463                                3.0                         3   \n",
       "1464                                4.0                         3   \n",
       "1465                                4.0                         3   \n",
       "\n",
       "      rating_gathers_information  rating_identifies_issues_opportunities   \n",
       "0                              2                                     2.0  \\\n",
       "1                              4                                     3.0   \n",
       "2                              2                                     2.0   \n",
       "3                              3                                     2.0   \n",
       "4                              2                                     3.0   \n",
       "...                          ...                                     ...   \n",
       "1461                           2                                     3.0   \n",
       "1462                           3                                     4.0   \n",
       "1463                           2                                     3.0   \n",
       "1464                           3                                     4.0   \n",
       "1465                           3                                     4.0   \n",
       "\n",
       "      rating_interprets_information  rating_involves_others   \n",
       "0                                 2                     3.0  \\\n",
       "1                                 4                     2.0   \n",
       "2                                 2                     2.0   \n",
       "3                                 2                     2.0   \n",
       "4                                 2                     2.0   \n",
       "...                             ...                     ...   \n",
       "1461                              3                     2.0   \n",
       "1462                              4                     4.0   \n",
       "1463                              2                     2.0   \n",
       "1464                              3                     4.0   \n",
       "1465                              3                     3.0   \n",
       "\n",
       "      rating_decision_making_final_score  \n",
       "0                                      2  \n",
       "1                                      6  \n",
       "2                                      2  \n",
       "3                                      3  \n",
       "4                                      3  \n",
       "...                                  ...  \n",
       "1461                                   2  \n",
       "1462                                   6  \n",
       "1463                                   2  \n",
       "1464                                   6  \n",
       "1465                                   5  \n",
       "\n",
       "[1466 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df=pd.read_csv(\"firstTry.csv\")\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ceb1f54b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Criterion 1 model\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[39m#Note: Once you find a satisfactory cross-validated score, you don't need to split the data, just run the model on everything\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39m#and predict the validate.csv on the second chunk\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y\u001b[39m=\u001b[39mdf[\u001b[39m'\u001b[39m\u001b[39mrating_chooses_appropriate_action\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      6\u001b[0m X_train, X_test, y_train, y_test\u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m      7\u001b[0m                                                 df[\u001b[39m'\u001b[39m\u001b[39mpredictor\u001b[39m\u001b[39m'\u001b[39m], y,\n\u001b[0;32m      8\u001b[0m                                                 test_size\u001b[39m=\u001b[39m\u001b[39m0.33\u001b[39m,\n\u001b[0;32m      9\u001b[0m                                                 random_state\u001b[39m=\u001b[39m\u001b[39m53\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39m#count_vectorizer = CountVectorizer(stop_words='english')\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39m#count_train = count_vectorizer.fit_transform(X_train.values)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m#count_test = count_vectorizer.transform(X_test.values)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m#Note: try other methods if you have time, like sentiment analysis, bag of words, or quanteda. \u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#Note: You might need to change max_features if it gives you an error in the next chunk, when predicting the validate dataset\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# Criterion 1 model\n",
    "\n",
    "#Note: Once you find a satisfactory cross-validated score, you don't need to split the data, just run the model on everything\n",
    "#and predict the validate.csv on the second chunk\n",
    "y=df['rating_chooses_appropriate_action']\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "\n",
    "#count_vectorizer = CountVectorizer(stop_words='english')\n",
    "#count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "#count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "#Converting words to numbers\n",
    "#Note: try other methods if you have time, like sentiment analysis, bag of words, or quanteda. \n",
    "#Note: You might need to change max_features if it gives you an error in the next chunk, when predicting the validate dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7, max_features=13000)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#Hyperparameter tuning\n",
    "#Note: use less parameters or make the ranges shorter if it's taking too long\n",
    "param_grid = {'max_depth':range(1, 7),\n",
    "                'learning_rate':np.arange(0.005, 0.3, 0.07),\n",
    "                 'n_estimators':np.arange(100, 2000, 200),\n",
    "                 'gamma':np.arange(0, 0.06, 0.01),\n",
    "                 'subsample':np.arange(0.5, 1, 0.1),\n",
    "                 'colsample_bytree':np.arange(0.5, 1, 0.1)}\n",
    "\n",
    "#Fitting model\n",
    "#Note: Hillclimbing methods could be used instead of gridsearch. This might be quicker. \n",
    "#Note: randomizedSearchCV() could be used instead of GridSearchCV() to make the algorithm quicker.\n",
    "#Note: try other models, like neural network classifier. We prefer a classification algorithm instead of regression. \n",
    "grid = GridSearchCV(xgb.XGBRegressor(random_state=0), \n",
    "                    param_grid=param_grid, cv=StratifiedShuffleSplit(100, random_state=1), verbose=3, scoring='neg_mean_squared_error')\n",
    "    \n",
    "grid.fit(tfidf_train, y_train)\n",
    "pred1 = grid.predict(tfidf_test)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "#Note: If you're using a classifier, you're going to have to change the metric to be the AUC or accuracy instead of the RMSE or r2\n",
    "print(\"Lowest RMSE: \", (-grid.best_score_)**(1/2.0))\n",
    "r2_score(y_test, pred1)\n",
    "#Use this for classification\n",
    "#metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ef6956f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Feature shape mismatch, expected: 19456, got 12474",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m tfidf_vectorizer \u001b[38;5;241m=\u001b[39m TfidfVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m, max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, max_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m19456\u001b[39m)\n\u001b[0;32m      3\u001b[0m count\u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(validation[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m pred1 \u001b[38;5;241m=\u001b[39m \u001b[43mnb_classifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1114\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, ntree_limit, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1114\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_array(predts):\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py:2269\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2265\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2266\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`shape` attribute is required when `validate_features` is True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2267\u001b[0m         )\n\u001b[0;32m   2268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features() \u001b[38;5;241m!=\u001b[39m data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m-> 2269\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2270\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature shape mismatch, expected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2271\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2272\u001b[0m         )\n\u001b[0;32m   2274\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   2275\u001b[0m     _array_interface,\n\u001b[0;32m   2276\u001b[0m     _is_cudf_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2279\u001b[0m     _transform_pandas_df,\n\u001b[0;32m   2280\u001b[0m )\n\u001b[0;32m   2282\u001b[0m enable_categorical \u001b[38;5;241m=\u001b[39m _has_categorical(\u001b[38;5;28mself\u001b[39m, data)\n",
      "\u001b[1;31mValueError\u001b[0m: Feature shape mismatch, expected: 19456, got 12474"
     ]
    }
   ],
   "source": [
    "#This chunk is predicting the test csv\n",
    "validation=pd.read_csv(\"validate.csv\")\n",
    "count= tfidf_vectorizer.fit_transform(validation['predictor'])\n",
    "pred1 = grid.predict(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f43dcc4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 3., 2., 2., 2., 2., 2.,\n",
       "       3., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 3., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 3.,\n",
       "       2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 3., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 3., 2., 2.,\n",
       "       3., 2., 3., 2., 2., 2., 2., 2., 2., 2., 3., 3., 2., 2., 2., 3., 2.,\n",
       "       2., 2., 2., 2., 2., 2., 3., 3., 2., 3., 2., 2., 2., 2., 2., 3., 2.,\n",
       "       2., 2., 3., 3., 2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2., 3., 2.,\n",
       "       2., 3., 2., 2., 2., 2., 3., 3., 3., 2., 2., 2., 2., 3., 3., 3., 2.,\n",
       "       2., 2., 2., 3., 2., 2., 2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fee9516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<487x12000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 114622 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf1862eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END activation=tanh, alpha=0.0001, hidden_layer_sizes=(50, 100, 50), learning_rate=constant, max_iter=500, solver=sgd;, score=0.640 total time=  43.1s\n"
     ]
    }
   ],
   "source": [
    "# Criterion 2 model\n",
    "\n",
    "#Note: Once you find a satisfactory cross-validated score, you don't need to split the data, just run the model on everything\n",
    "#and predict the validate.csv on the second chunk\n",
    "y=df['rating_commits_to_action']\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "\n",
    "#count_vectorizer = CountVectorizer(stop_words='english')\n",
    "#count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "#count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "#Converting words to numbers\n",
    "#Note: try other methods if you have time, like sentiment analysis, bag of words, or quanteda. \n",
    "#Note: You might need to change max_features if it gives you an error in the next chunk, when predicting the validate dataset\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7, max_features=12474)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "#Hyperparameter tuning\n",
    "#Note: use less parameters or make the ranges shorter if it's taking too long\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,100,50), (100,)],\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': [0.0001],\n",
    "    'learning_rate': ['constant'],\n",
    "    'max_iter': [500]\n",
    "}\n",
    "\n",
    "\n",
    "#Fitting model\n",
    "#Note: Hillclimbing methods could be used instead of gridsearch. This might be quicker. \n",
    "#Note: randomizedSearchCV() could be used instead of GridSearchCV() to make the algorithm quicker.\n",
    "#Note: try other models, like neural network classifier. We prefer a classification algorithm instead of regression. \n",
    "grid = GridSearchCV(MLPClassifier(random_state=0), \n",
    "                    param_grid=param_grid, cv=5, verbose=3, scoring='accuracy')\n",
    "    \n",
    "grid.fit(tfidf_train, y_train)\n",
    "pred2 = grid.predict(tfidf_test)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "#Note: If you're using a classifier, you're going to have to change the metric to be the AUC or accuracy instead of the RMSE or r2\n",
    "#print(\"Lowest RMSE: \", (-grid.best_score_)**(1/2.0))\n",
    "#r2_score(y_test, pred2)\n",
    "accuracy = accuracy_score(y_test, pred2)\n",
    "print(\"Accuracy score: \", accuracy)\n",
    "#Use this for classification\n",
    "#metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d454c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 3, 3, 4, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 4, 4,\n",
       "       3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 4, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 3,\n",
       "       3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 2, 2, 3, 3, 4, 4, 4, 3, 3, 3, 4, 3,\n",
       "       3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3,\n",
       "       3, 2, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3,\n",
       "       2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3,\n",
       "       3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 4, 2, 2, 3, 3, 3, 3, 2, 3, 2, 3, 3, 3, 3, 2,\n",
       "       3, 3, 2, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3,\n",
       "       4, 3, 3, 3, 4, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3,\n",
       "       4, 3, 3, 3, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 3, 4,\n",
       "       4, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 4, 2, 3, 3, 4, 3, 3, 3, 3, 3,\n",
       "       3, 4, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 3, 3, 4, 3, 3,\n",
       "       3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 4, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 4, 3, 4, 3, 4, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 4, 3],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2.round()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7514ebc6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 12474 features, but MLPClassifier is expecting 13000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m validation\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mvalidate.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m count\u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39mtransform(validation[\u001b[39m'\u001b[39m\u001b[39mpredictor\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m pred_2 \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mpredict(count)\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:499\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[39m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \n\u001b[0;32m    483\u001b[0m \u001b[39mOnly available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[39m    the best found parameters.\u001b[39;00m\n\u001b[0;32m    497\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    498\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 499\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbest_estimator_\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1156\u001b[0m, in \u001b[0;36mMLPClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1143\u001b[0m \u001b[39m\"\"\"Predict using the multi-layer perceptron classifier.\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \n\u001b[0;32m   1145\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1153\u001b[0m \u001b[39m    The predicted classes.\u001b[39;00m\n\u001b[0;32m   1154\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1155\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m-> 1156\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_predict(X)\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:1160\u001b[0m, in \u001b[0;36mMLPClassifier._predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_predict\u001b[39m(\u001b[39mself\u001b[39m, X, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1159\u001b[0m     \u001b[39m\"\"\"Private predict method with optional input validation\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1160\u001b[0m     y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_pass_fast(X, check_input\u001b[39m=\u001b[39;49mcheck_input)\n\u001b[0;32m   1162\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1163\u001b[0m         y_pred \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:202\u001b[0m, in \u001b[0;36mBaseMultilayerPerceptron._forward_pass_fast\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[39m\"\"\"Predict using the trained model\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \n\u001b[0;32m    185\u001b[0m \u001b[39mThis is the same as _forward_pass but does not record the activations\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[39m    The decision function of the samples for each class in the model.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \u001b[39mif\u001b[39;00m check_input:\n\u001b[1;32m--> 202\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    204\u001b[0m \u001b[39m# Initialize first layer\u001b[39;00m\n\u001b[0;32m    205\u001b[0m activation \u001b[39m=\u001b[39m X\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:588\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 588\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    590\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\miked\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:389\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    390\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    391\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    392\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 12474 features, but MLPClassifier is expecting 13000 features as input."
     ]
    }
   ],
   "source": [
    "#This chunk is predicting the test csv\n",
    "validation=pd.read_csv(\"validate.csv\")\n",
    "count= tfidf_vectorizer.transform(validation['predictor'])\n",
    "pred_2 = grid.predict(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7298315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47368421052631576"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criterion 3 model\n",
    "\n",
    "y=round(df['rating_gathers_information'])\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1dc7b0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6469298245614035"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criterion 4 model\n",
    "\n",
    "y=round(df['rating_identifies_issues_opportunities'])\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be888d39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6162280701754386"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criterion 5 model\n",
    "\n",
    "y=round(df['rating_interprets_information'])\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dfea0cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5153508771929824"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criterion 6 model\n",
    "\n",
    "y=round(df['rating_involves_others'])\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45868851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criterion 7 model\n",
    "\n",
    "y=round(df['rating_decision_making_final_score'])\n",
    "X_train, X_test, y_train, y_test= train_test_split(\n",
    "                                                df['predictor'], y,\n",
    "                                                test_size=0.33,\n",
    "                                                random_state=53)\n",
    "count_vectorizer = CountVectorizer(stop_words='english')\n",
    "count_train = count_vectorizer.fit_transform(X_train.values)\n",
    "count_test = count_vectorizer.transform(X_test.values)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "nb_classifier.fit(count_train, y_train)\n",
    "pred = nb_classifier.predict(count_test)\n",
    "metrics.accuracy_score(y_test, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd4cce58ff97b04034434c7bcfd2b9ee607eeae56f8da9cc1802f0e7ac6ee036"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
